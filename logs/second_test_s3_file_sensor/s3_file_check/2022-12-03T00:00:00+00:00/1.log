[2022-12-04 18:48:01,197] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: second_test_s3_file_sensor.s3_file_check scheduled__2022-12-03T00:00:00+00:00 [queued]>
[2022-12-04 18:48:01,203] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: second_test_s3_file_sensor.s3_file_check scheduled__2022-12-03T00:00:00+00:00 [queued]>
[2022-12-04 18:48:01,203] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-12-04 18:48:01,203] {taskinstance.py:1250} INFO - Starting attempt 1 of 3
[2022-12-04 18:48:01,203] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-12-04 18:48:01,210] {taskinstance.py:1270} INFO - Executing <Task(S3KeySensor): s3_file_check> on 2022-12-03 00:00:00+00:00
[2022-12-04 18:48:01,213] {standard_task_runner.py:52} INFO - Started process 216 to run task
[2022-12-04 18:48:01,216] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'second_test_s3_file_sensor', 's3_file_check', 'scheduled__2022-12-03T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/s3_file_sensor2.py', '--cfg-path', '/tmp/tmpd64p5mp_', '--error-file', '/tmp/tmp12to4gbq']
[2022-12-04 18:48:01,216] {standard_task_runner.py:80} INFO - Job 5: Subtask s3_file_check
[2022-12-04 18:48:01,247] {logging_mixin.py:109} INFO - Running <TaskInstance: second_test_s3_file_sensor.s3_file_check scheduled__2022-12-03T00:00:00+00:00 [running]> on host a10df1f15deb
[2022-12-04 18:48:01,266] {taskinstance.py:1747} WARNING - We expected to get frame set in local storage but it was not. Please report this as an issue with full logs at https://github.com/apache/***/issues/new
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column xcom.execution_date does not exist
LINE 1: ...le_sensor' AND xcom.task_id = 's3_file_check' AND xcom.execu...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1340, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1437, in _execute_task_with_callbacks
    self.clear_xcom_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 803, in clear_xcom_data
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 437, in clear
    return query.delete()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3926, in delete
    delete_op.exec_()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1697, in exec_
    self._do_exec()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1930, in _do_exec
    self._execute_stmt(delete_stmt)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1702, in _execute_stmt
    self.result = self.query._execute_crud(stmt, self.mapper)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3568, in _execute_crud
    return conn.execute(stmt, self._params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column xcom.execution_date does not exist
LINE 1: ...le_sensor' AND xcom.task_id = 's3_file_check' AND xcom.execu...
                                                             ^

[SQL: DELETE FROM xcom WHERE xcom.dag_id = %(dag_id_1)s AND xcom.task_id = %(task_id_1)s AND xcom.execution_date = %(execution_date_1)s]
[parameters: {'dag_id_1': 'second_test_s3_file_sensor', 'task_id_1': 's3_file_check', 'execution_date_1': datetime.datetime(2022, 12, 3, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: http://sqlalche.me/e/13/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1741, in get_truncated_error_traceback
    execution_frame = _TASK_EXECUTION_FRAME_LOCAL_STORAGE.frame
AttributeError: '_thread._local' object has no attribute 'frame'
[2022-12-04 18:48:01,270] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column xcom.execution_date does not exist
LINE 1: ...le_sensor' AND xcom.task_id = 's3_file_check' AND xcom.execu...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1340, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1437, in _execute_task_with_callbacks
    self.clear_xcom_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 803, in clear_xcom_data
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 437, in clear
    return query.delete()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3926, in delete
    delete_op.exec_()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1697, in exec_
    self._do_exec()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1930, in _do_exec
    self._execute_stmt(delete_stmt)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1702, in _execute_stmt
    self.result = self.query._execute_crud(stmt, self.mapper)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 3568, in _execute_crud
    return conn.execute(stmt, self._params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column xcom.execution_date does not exist
LINE 1: ...le_sensor' AND xcom.task_id = 's3_file_check' AND xcom.execu...
                                                             ^

[SQL: DELETE FROM xcom WHERE xcom.dag_id = %(dag_id_1)s AND xcom.task_id = %(task_id_1)s AND xcom.execution_date = %(execution_date_1)s]
[parameters: {'dag_id_1': 'second_test_s3_file_sensor', 'task_id_1': 's3_file_check', 'execution_date_1': datetime.datetime(2022, 12, 3, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-12-04 18:48:01,277] {taskinstance.py:1288} INFO - Marking task as UP_FOR_RETRY. dag_id=second_test_s3_file_sensor, task_id=s3_file_check, execution_date=20221203T000000, start_date=20221204T184801, end_date=20221204T184801
[2022-12-04 18:48:01,282] {standard_task_runner.py:98} ERROR - Failed to execute job 5 for task s3_file_check ((psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 's3_file_check', 'dag_id': 'second_test_s3_file_sensor', 'execution_date': datetime.datetime(2022, 12, 3, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 12, 4, 18, 48, 1, 197748, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 12, 4, 18, 48, 1, 276863, tzinfo=Timezone('UTC')), 'duration': 0}]
(Background on this error at: http://sqlalche.me/e/13/f405); 216)
[2022-12-04 18:48:01,307] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-12-04 18:48:01,323] {taskinstance.py:1288} INFO - Marking task as UP_FOR_RETRY. dag_id=second_test_s3_file_sensor, task_id=s3_file_check, execution_date=20221203T000000, start_date=20221204T184801, end_date=20221204T184801
